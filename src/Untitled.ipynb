{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['20190524_3', '20191108_18', '20191028_15', '20190803_19', '20191108_15', '20190524_7', '20191026_10', '20191027_7', '20191026_8', '20191129_12', '20190524_4', '20191129_16', '20191129_9', '20190803_17', '20191108_19', '20191129_5', '20191028_18', '20190524_5', '20191129_14', '20190803_18', '20191129_6', '20190729_12', '20190729_10', '20190803_13', '20191028_17', '20190729_11', '20191026_9', '20190803_11', '20191026_6', '20190803_9', '20191108_22', '20190729_13', '20190803_14', '20190803_7', '20190729_15', '20190524_8', '20191026_7', '20191108_16', '20191129_15', '20191028_19', '20190803_8', '20191028_8', '20190524_6', '20191027_8']) dict_keys(['20190524_3', '20191108_18', '20191028_15', '20190803_19', '20191108_15', '20190524_7', '20191026_10', '20191027_7', '20191026_8', '20191129_12', '20190524_4', '20191129_16', '20191129_9', '20190803_17', '20191108_19', '20191129_5', '20191028_18', '20190524_5', '20191129_14', '20190803_18', '20191129_6', '20190729_12', '20190729_10', '20190803_13', '20191028_17', '20190729_11', '20191026_9', '20190803_11', '20191026_6', '20190803_9', '20191108_22', '20190729_13', '20190803_14', '20190803_7', '20190729_15', '20190524_8', '20191026_7', '20191108_16', '20191129_15', '20191028_19', '20190803_8', '20191028_8', '20190524_6', '20191027_8']) "
     ]
    }
   ],
   "source": [
    "path = join_path((pathlst['measure'],[basename,'rok']))\n",
    "data_rok = load_safe(path)\n",
    "\n",
    "def poissonfit(arr):\n",
    "    from scipy.optimize import curve_fit\n",
    "    from scipy.stats import poisson\n",
    "    y, bin_edges = np.histogram(arr, bins=freq_bins - 0.5, density=True)\n",
    "    bin_middles = freq_bins.astype(float)[:-1]#(bin_edges[1:] + bin_edges[:-1])/2\n",
    "    fit_function = lambda k, lamb:poisson.pmf(k, lamb)\n",
    "    parameters, cov_matrix = curve_fit(fit_function, bin_middles, y)\n",
    "    yfit = fit_function(freq_bins, *parameters)\n",
    "    return y,yfit\n",
    "\n",
    "\n",
    "path = join_path((pathlst['measure'],[basename,'rok']))\n",
    "data_rok = load_safe(path)\n",
    "\n",
    "speed_bins = np.arange(20)\n",
    "freq_bins = np.arange(12)\n",
    "recur_bins = np.arange(51)\n",
    "\n",
    "stacked = [get(data_rok,'speed',np.hstack,lambda phenotype,x: np.histogram(x,bins=speed_bins,density=True)[0]),\n",
    "           get(data_rok,'speed',None,lambda phenotype,x: 1-(np.histogram(x,bins=speed_bins,density=True)[0][:3]).sum()),\n",
    "           get(data_rok,'duration','arr',None),\n",
    "           get(data_rok,'area','arr',None),\n",
    "           get(data_rok,'freq',np.hstack,lambda phenotype,x: poissonfit(x)),\n",
    "           get(data_rok,'recur',np.hstack,lambda phenotype,x: np.histogram(x,bins=recur_bins,density=True)[0])\n",
    "          ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            phenotype LabelG LabelR  tRes  nEnd    note contractility  \\\n",
      "ID                                                                      \n",
      "20210409_7       plst    ROK    NMY   0.6   400  SD3050           NaN   \n",
      "20210410_11     unc60    ROK    NMY   0.6   300  SD3050           NaN   \n",
      "20210420_29       spd    ROK    NMY   0.6   350  SD3050           NaN   \n",
      "20210420_23     mel11    ROK    NMY   0.6   250  SD3050           NaN   \n",
      "20190729_10       ani    ROK     LA   0.6   450  SD3050           NaN   \n",
      "20190803_19       cyk    ROK     LA   0.6   350  SD3050  intermediate   \n",
      "20191026_8        pfn    ROK     LA   0.6   350  SD3050       strong2   \n",
      "20191108_15       nmy    ROK   None   0.6   520    SD30           NaN   \n",
      "\n",
      "                comment  \n",
      "ID                       \n",
      "20210409_7    EXAMPLE_6  \n",
      "20210410_11  EXAMPLE_10  \n",
      "20210420_29  EXAMPLE_11  \n",
      "20210420_23   EXAMPLE_7  \n",
      "20190729_10   EXAMPLE_5  \n",
      "20190803_19  EXAMPLE_13  \n",
      "20191026_8    EXAMPLE_9  \n",
      "20191108_15   EXAMPLE_9  \n",
      "dict_keys(['img', 'imr', 'nzzs', 'outline', 'RC']) dict_keys(['img', 'imr', 'nzzs', 'outline', 'RC']) dict_keys(['img', 'imr', 'nzzs', 'outline', 'RC']) dict_keys(['img', 'imr', 'nzzs', 'outline', 'RC']) dict_keys(['img', 'imr', 'nzzs', 'outline', 'RC']) dict_keys(['img', 'imr', 'nzzs', 'outline', 'RC']) dict_keys(['img', 'imr', 'nzzs', 'outline', 'RC']) dict_keys(['img', 'imr', 'nzzs', 'outline', 'RC']) "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (5792, 1288) to (5792, 1296) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (2896, 1288) to (2896, 1296) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (5792, 1288) to (5792, 1296) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def rok_ts_kmgh(nzzs,img_raw,RC):\n",
    "    from imagestack import blur_stk\n",
    "    img_raw = blur_stk(img_raw,4,divide(1.2,tRes))\n",
    "\n",
    "    from imagestack import crop_group_z\n",
    "    zs,zgroups = crop_group_z(nzzs,tRes)\n",
    "\n",
    "    from rotate_crop import rotate_crop,kmgh\n",
    "    img = rotate_crop(img_raw,zs,RC)\n",
    "\n",
    "    img_kmgh, x_kmgh = kmgh(img,tRes,H=7)\n",
    "\n",
    "    return img,img_kmgh,x_kmgh\n",
    "\n",
    "def figure1():# SD embryo ROK raw and kymograph\n",
    "    minmax_g_dict = {'spd':(100,900),'nmy':(400,900),'mel11':(200,700),'plst':(200,800),\n",
    "                    'unc60':(200,900),'cyk':(300,750),'pfn':(300,800),'ani':(300,900)}\n",
    "\n",
    "    IDs = infolst[infolst.apply(lambda x: \n",
    "        str(x['comment']).startswith('EXAMPLE_')\n",
    "        , axis=1)].index.values.astype(str)\n",
    "\n",
    "    print(infolst.loc[IDs])\n",
    "    movies = {}\n",
    "    for ID in IDs:\n",
    "        globals().update({'ID':ID, **dict(infolst.loc[ID])})\n",
    "\n",
    "        result_raw = load_safe(join_path((pathlst['pipeline'],'run_raw',[phenotype,ID])))\n",
    "        img,img_kmgh,x_kmgh = rok_ts_kmgh(result_raw['nzzs'][2:],result_raw['img'],result_raw['RC'])\n",
    "\n",
    "        minmax_g = minmax_g_dict[phenotype]\n",
    "        from colorcode import standarize, standarized_to_rgb\n",
    "        img,img_kmgh = standarized_to_rgb(standarize(img, *minmax_g)),standarized_to_rgb(standarize(img_kmgh, *minmax_g))\n",
    "\n",
    "        idx_kmgh = int(comment.split('_')[1])-1\n",
    "        tifffile.imsave(safe_path(pjoin(pathlst['paper'],'f1','-'.join([phenotype,ID])+'_img_kmgh.tif')), img_kmgh[idx_kmgh])\n",
    "        \n",
    "        imgg = img.copy()\n",
    "        #imgg[:,x_kmgh[idx_kmgh]] = 255\n",
    "        tifffile.imsave(join_path((pathlst['paper'],'f1','-'.join([phenotype,ID])+'_img.tif')), imgg)\n",
    "\n",
    "        movies[phenotype] = img\n",
    "    return movies\n",
    "\n",
    "def figure1_stack_save(movies, info):\n",
    "    H2 = 40\n",
    "    titleshape = list(movies['spd'].shape)\n",
    "    titleshape[1] = H2\n",
    "    title = np.full(titleshape,0,dtype=np.uint8)\n",
    "\n",
    "    row1 = [np.hstack([title,np.hstack([title,movies[phenotype]])]) for phenotype in info.keys()]\n",
    "    color = (255,255,255)\n",
    "    import cv2\n",
    "    dt = 0.6\n",
    "    for i in range(row1[0].shape[0]):\n",
    "        cv2.putText(row1[0][i], str(round(dt*i,1))+' S', (30,H2-10), cv2.FONT_HERSHEY_SIMPLEX , 1, color, 2)\n",
    "        cv2.line(row1[0][i], (20,240+H2), (20+50,240+H2), color, 2)# scale bar 5um\n",
    "        for j,txt in enumerate(info.values()):\n",
    "            cv2.putText(row1[j][i], txt, (120,2*H2-10), cv2.FONT_HERSHEY_SIMPLEX , 1, color, 2)\n",
    "    from colorcode import stk_boarder,stk_upsizexy\n",
    "    im = stk_upsizexy(np.dstack([stk_boarder(temp) for temp in row1]))\n",
    "    \n",
    "    saveMP4(join_path((pathlst['paper'],'movies',['raw','_'.join(info.keys())])),im,40)\n",
    "\n",
    "#'''\n",
    "movies=figure1()\n",
    "figure1_stack_save(movies, {'spd':'Control','cyk':'cyk-1(RNAi)','pfn':'pfn-1(RNAi)','ani':'ani-1(RNAi)'})\n",
    "figure1_stack_save(movies, {'spd':'Control','unc60':'unc-60(RNAi)'})\n",
    "figure1_stack_save(movies, {'spd':'Control','nmy':'nmy-2(ts)','mel11':'mel-11(RNAi)','plst':'plst-1(tm2455)'})\n",
    "#'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed\n",
      "spd cyk 0.0 45496 82638\n",
      "spd ani 0.0 45496 47574\n",
      "cyk ani 0.0 82638 47574\n",
      "spd nmy 0.0 45496 54105\n",
      "cyk cyk+nmy 0.0 82638 62923\n",
      "ani ani+nmy 0.0 47574 86216\n",
      "\n",
      "duration\n",
      "spd cyk 0.06 6 8\n",
      "spd ani 0.009 6 5\n",
      "cyk ani 0.413 8 5\n",
      "spd nmy 0.009 6 7\n",
      "cyk cyk+nmy 0.062 8 5\n",
      "ani ani+nmy 0.126 5 7\n",
      "\n",
      "area\n",
      "spd cyk 0.001 6 8\n",
      "spd ani 0.004 6 5\n",
      "cyk ani 0.357 8 5\n",
      "spd nmy 0.309 6 7\n",
      "cyk cyk+nmy 0.002 8 5\n",
      "ani ani+nmy 0.165 5 7\n",
      "\n",
      "freq\n",
      "spd cyk 0.0 615914 561054\n",
      "spd ani 0.0 615914 349737\n",
      "cyk ani 0.0 561054 349737\n",
      "spd nmy 0.0 615914 607577\n",
      "cyk cyk+nmy 0.0 561054 562565\n",
      "ani ani+nmy 0.0 349737 561507\n",
      "\n",
      "recur\n",
      "spd cyk 0.0 555293 1816302\n",
      "spd ani 0.0 555293 941121\n",
      "cyk ani 0.0 1816302 941121\n",
      "spd nmy 0.0 555293 742353\n",
      "cyk cyk+nmy 0.0 1816302 1000105\n",
      "ani ani+nmy 0.0 941121 1755149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_significance(data):\n",
    "    from scipy.stats import mannwhitneyu\n",
    "    for phenotype1,phenotype2 in [\n",
    "        ('spd','cyk'),('spd','ani'),('cyk','ani'),\n",
    "        ('spd','nmy'),('cyk','cyk+nmy'),('ani','ani+nmy')]:\n",
    "        data1,data2 = data[phenotype1],data[phenotype2]\n",
    "        stat, p = mannwhitneyu(data1,data2)\n",
    "        print(phenotype1,phenotype2,round(p,3),len(data1),len(data2))\n",
    "    \n",
    "    \n",
    "for name in ['speed','duration','area','freq','recur']:\n",
    "    print(name)\n",
    "    test_significance(get(data_rok,name,np.hstack,None))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def fade(msk,N):\n",
    "    result = np.full(msk.shape,np.nan,dtype=np.float32)\n",
    "    for z in range(N,msk.shape[0]):\n",
    "        zs = np.arange(z-N,z+1)\n",
    "        for zz in zs:\n",
    "            result[z,msk[zz]] = (zz-zs[0])/(zs[-1]-zs[0])\n",
    "    return result\n",
    "\n",
    "def fade_msks(rgb,msks,outline,RC):\n",
    "    N = 3\n",
    "    for msk,color in msks:\n",
    "        imshape = msk.shape\n",
    "        color = matplotlib.colors.to_rgb(color)\n",
    "        faded = fade(msk,N)\n",
    "        m = ~np.isnan(faded)\n",
    "        rgb[m] = gradient_saturated_gray(color,235/255,faded,-0.5,1,reverse=True)[m]\n",
    "    \n",
    "    rgb[:,~outline] = 255\n",
    "    from rotate_crop import rgb_rotate_crop\n",
    "    rgb = rgb_rotate_crop(rgb,None,RC)\n",
    "    return rgb\n",
    "\n",
    "def draw_line(im,xy0,xy1,value,thickness):\n",
    "    mask = np.zeros(im.shape[:2],dtype=np.uint8)\n",
    "    import cv2\n",
    "    mask = cv2.line(mask,tuple(np.flip(xy0)),tuple(np.flip(xy1)),255,thickness)>0\n",
    "    im[np.where(mask)]=value\n",
    "    return im\n",
    "\n",
    "def cc_cum(graph,cc,blobs,imshape,outline,RC):\n",
    "    for pz in blobs.keys():\n",
    "        for b in blobs[pz]:\n",
    "            b.center = b.pixels.mean(0).astype(int)\n",
    "    darkcolors = dark_unique_colors()\n",
    "    result = np.full(list(imshape[1:])+[3],235,dtype=np.uint8)\n",
    "    from spread import component_duration,component_get_zxy\n",
    "    cc = [component for component in cc if component_duration(component)>5]\n",
    "    print(len(cc))\n",
    "    import cv2\n",
    "    for rank,component in enumerate(cc):\n",
    "        color = gradient_saturated_gray(darkcolors[rank],1,0.2,0,1,reverse=False)\n",
    "        color = ( int (color [ 0 ]), int (color [ 1 ]), int (color [ 2 ])) \n",
    "        \n",
    "        for pz,j in component:\n",
    "            b = blobs[pz][j]\n",
    "            b_center = b.center\n",
    "            for npz,nj in graph.neighbors((pz,j)):\n",
    "                n_center = blobs[npz][nj].center\n",
    "                cv2.line(result,tuple(np.flip(b_center)),tuple(np.flip(n_center)),color,2)\n",
    "    result[~outline] = 255\n",
    "    RC.theta = 0\n",
    "    from rotate_crop import rgb_rotate_crop\n",
    "    result = rgb_rotate_crop(result,None,RC)\n",
    "    return result\n",
    "\n",
    "def cc_cum_largest(graph,cc,blobs,imshape,outline,RC):\n",
    "    darkcolors = dark_unique_colors()\n",
    "    result = np.full(list(imshape[1:])+[3],235,dtype=np.uint8)\n",
    "    rank = 0\n",
    "    color = gradient_saturated_gray(darkcolors[rank],1,0.2,0,1,reverse=False)\n",
    "    from spread import component_get_zxy\n",
    "    zxy = component_get_zxy(blobs,cc[0])\n",
    "    result[zxy[:,1],zxy[:,2]] = color\n",
    "    result[~outline] = 255\n",
    "    RC.theta = 0\n",
    "    from rotate_crop import rgb_rotate_crop\n",
    "    result = rgb_rotate_crop(result,None,RC)\n",
    "    return result\n",
    "\n",
    "def cc_cum_kmgh(graph,cc,blobs,imshape,outline,RC):\n",
    "    darkcolors = dark_unique_colors()\n",
    "    result = np.full(list(imshape)+[3],235,dtype=np.uint8)\n",
    "    from spread import component_duration,component_get_zxy\n",
    "    cc = [component for component in cc if component_duration(component)>5]\n",
    "    for rank,component in enumerate(cc):\n",
    "        color = gradient_saturated_gray(darkcolors[rank],1,0.2,0,1,reverse=False)\n",
    "        zxy = component_get_zxy(blobs,component)\n",
    "        result[zxy[:,0],zxy[:,1],zxy[:,2]] = color\n",
    "    result[:,~outline] = 255\n",
    "    RC.theta = 0\n",
    "    from rotate_crop import rgb_rotate_crop\n",
    "    result = rgb_rotate_crop(result,None,RC)\n",
    "    return result[:,120]\n",
    "\n",
    "\n",
    "IDs = ['20190524_7','20190803_19','20190729_12']#\n",
    "\n",
    "for ID in IDs:\n",
    "    data = data_examples[ID]\n",
    "    phenotype = infolst.loc[ID]['phenotype']\n",
    "    im_cc_cum = cc_cum(data['graph'],data['cc'],data['blobs'],data['imshape'],data['outline'],data['RC'])\n",
    "    path = safe_path(pjoin(pathlst['paper'],'f3','cccum_'+phenotype+'.tif'))\n",
    "    tifffile.imsave(path,im_cc_cum)\n",
    "\n",
    "    im_cc_cum_largest = cc_cum_largest(data['graph'],data['cc'],data['blobs'],data['imshape'],data['outline'],data['RC'])\n",
    "    path = safe_path(pjoin(pathlst['paper'],'f3','cccumlargest_'+phenotype+'.tif'))\n",
    "    tifffile.imsave(path,im_cc_cum_largest)\n",
    "    \n",
    "    im_cc_cum_kmgh = cc_cum_kmgh(data['graph'],data['cc'],data['blobs'],data['imshape'],data['outline'],data['RC'])\n",
    "    path = safe_path(pjoin(pathlst['paper'],'f3','cccumkmgh_'+phenotype+'.tif'))\n",
    "    tifffile.imsave(path,im_cc_cum_kmgh)\n",
    "\n",
    "\n",
    "    from velocity import erodemask\n",
    "    erode_outline = erodemask(data['outline'],10)\n",
    "\n",
    "    actin = data['R']['raw_disk'][:100]\n",
    "    actin = standarize_colormap(actin,40,800,'gray')\n",
    "    \n",
    "    msk_slow,msk_fast = msk_speed(data['points'],data['imshape'])\n",
    "    msk_slow[:,~erode_outline] = False\n",
    "    msk_fast[:,~erode_outline] = False\n",
    "    tifffile.imsave('speed_'+infolst.loc[ID]['phenotype']+'.tif',\n",
    "                    fade_msks(actin.copy(),((msk_fast,'darkorange'),(msk_slow,'dodgerblue')),outline,data['RC']))    \n",
    "    \n",
    "    msk_short,msk_long = msk_recurrence(data['NEWEXC'],outline)\n",
    "    msk_short[:,~erode_outline] = False\n",
    "    msk_long[:,~erode_outline] = False\n",
    "    tifffile.imsave('recur_'+infolst.loc[ID]['phenotype']+'.tif',\n",
    "                    fade_msks(actin.copy(),((msk_short,'darkorange'),(msk_long,'dodgerblue')),outline,data['RC']))\n",
    "    \n",
    "def fig_pfn(fig,recur):\n",
    "    N = len(recur['pfn'])\n",
    "    axes3 = addax(fig,L=1,W=1,T=1,H=N,ncols=1,nrows=N,wspace=2,hspace=0.2,sharex='col',sharey='col')#,sharey='all'\n",
    "    axes3tw = addax(fig,L=2.5,W=0.2,T=1,H=N,ncols=1,nrows=N,wspace=2,hspace=0.15,sharex='col',sharey='col')\n",
    "    \n",
    "    recur_bins = np.arange(51)\n",
    "    \n",
    "    from histogram import step\n",
    "    for i,(ID,arr) in enumerate(recur['pfn'].items()):\n",
    "        recur_hist = np.histogram(arr,bins=recur_bins,density=True)[0]\n",
    "        x,y = step(recur_bins*1.2,recur_hist).T\n",
    "        axes3[i].fill_between(x[:-2],y[:-2],color='k',alpha=0.5,lw=0)\n",
    "        axes3tw[i].plot(x[-1],y[-1],'x',color='k')\n",
    "        \n",
    "    axes3[-1].set(xlim=[0,60],xlabel='      Time before re-activation (s)',ylim=[0,0.06],xticks=[0,20,40,60])\n",
    "    axes3[int(N/2)].set(ylabel='Density')\n",
    "    for ax3tw in axes3tw:\n",
    "        ax3tw.set(xlim=[59,61],xticks=[60],xticklabels=['>60'],ylim=[0,0.6],yticks=[0,0.5])\n",
    "        \n",
    "        \n",
    "\n",
    "figure(join_path((pathlst['paper'],'f3')),[get(data_rok,'recur',None,None)],fig_pfn)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
